# Mathematics_for_Machine_Learning

<p align="center"><img width="auto" src="https://github.com/TheKidPadra/Mathematics_for_Machine_Learning/blob/main/Assets/maxresdefault.png" /></p>

Become Proficient in the Mathematical Foundations of AI and Machine Learning. The Mathematics for Machine Learning and Data Science specialization offers a beginner-friendly approach to mastering the fundamental mathematical toolkit of machine learning, including calculus, linear algebra, statistics, and probability.

## WHAT YOU WILL LEARN
- Implement mathematical concepts using real-world data
- Derive PCA from a projection perspective
- Understand how orthogonal projections work
- Master PCA

---

## SKILLS YOU WILL GAIN
- Eigenvalues And Eigenvectors
- Principal Component Analysis (PCA)
- Multivariable Calculus
- Linear Algebra
- Linear Regression
- Linear Equation
- Eigenvalues And Eigenvectors
- Transformation Matrix
- Vector Calculus
- Gradient Descent
- Mathematical Optimization
- Dimensionality Reduction

---

## About this Specialization

- For many advanced courses in Machine Learning and Data Science, it's common to realize the need for a refresher on the foundational mathematics. Topics that may have been previously studied in school or university may not have been taught in a context that is easily relatable to Computer Science, resulting in difficulties in applying them to real-world applications. This specialization is designed to bridge that gap by providing a comprehensive understanding of the underlying mathematics and how it relates to Machine Learning and Data Science.

- The first course focuses on Linear Algebra, covering its definition and its relevance to data analysis. It delves into vectors, matrices, and their operations.
- The second course, Multivariate Calculus, builds upon the concepts learned in the first course and explores optimization techniques for fitting functions to data. It starts with an introduction to calculus and then applies the principles of matrices and vectors to data fitting.
- The third course, Dimensionality Reduction with Principal Component Analysis, utilizes the mathematical foundations from the previous two courses to compress high-dimensional data. This intermediate-level course requires proficiency in Python and numpy.

Upon completing this specialization, you will have acquired the essential mathematical knowledge necessary to progress to more advanced courses in machine learning with confidence.

---

## Applied Learning Project

- Throughout this specialization, you will have the opportunity to apply the skills you have acquired by completing assignments that involve working on mini-projects with Python within interactive notebooks. These notebooks are user-friendly tools that facilitate the application of your knowledge to real-world problems. For instance, you may utilize linear algebra to calculate the page rank of a simulated internet, apply multivariate calculus to train your own neural network, perform non-linear least squares regression to fit a model to a data set, and employ principal component analysis to determine features of the MNIST digits data set.


-------------------------------------------------------------------------------------------------------------
### COURSE 1
### Mathematics for Machine Learning: Linear Algebra

- In this course on Linear Algebra we look at what linear algebra is and how it relates to vectors and matrices. Then we look through what vectors and matrices are and how to work with them, including the knotty problem of eigenvalues and eigenvectors, and how to use these to solve problems. Finally  we look at how to use these to do fun things with datasets - like how to rotate images of faces and how to extract eigenvectors to look at how the Pagerank algorithm works.
- Since we're aiming at data-driven applications, we'll be implementing some of these ideas in code, not just on pencil and paper. Towards the end of the course, you'll write code blocks and encounter Jupyter notebooks in Python, but don't worry, these will be quite short, focussed on the concepts, and will guide you through if you‚Äôve not coded before.
- At the end of this course you will have an intuitive understanding of vectors and matrices that will help you bridge the gap into linear algebra problems, and how to apply these concepts to machine learning.

### COURSE 2
### Mathematics for Machine Learning: Multivariate Calculus

- This course offers a brief introduction to the multivariate calculus required to build many common machine learning techniques. We start at the very beginning with a refresher on the ‚Äúrise over run‚Äù formulation of a slope, before converting this to the formal definition of the gradient of a function. We then start to build up a set of tools for making calculus easier and faster. Next, we learn how to calculate vectors that point up hill on multidimensional surfaces and even put this into action using an interactive game. We take a look at how we can use calculus to build approximations to functions, as well as helping us to quantify how accurate we should expect those approximations to be. We also spend some time talking about where calculus comes up in the training of neural networks, before finally showing you how it is applied in linear regression models. This course is intended to offer an intuitive understanding of calculus, as well as the language necessary to look concepts up yourselves when you get stuck. Hopefully, without going into too much detail, you‚Äôll still come away with the confidence to dive into some more focused machine learning courses in future.

### COURSE 3
### Mathematics for Machine Learning: PCA

- This intermediate-level course introduces the mathematical foundations to derive Principal Component Analysis (PCA), a fundamental dimensionality reduction technique. We'll cover some basic statistics of data sets, such as mean values and variances, we'll compute distances and angles between vectors using inner products and derive orthogonal projections of data onto lower-dimensional subspaces. Using all these tools, we'll then derive PCA as a method that minimizes the average squared reconstruction error between data points and their reconstruction.
- At the end of this course, you'll be familiar with important mathematical concepts and you can implement PCA all by yourself. If you‚Äôre struggling, you'll find a set of jupyter notebooks that will allow you to explore properties of the techniques and walk you through what you need to do to get on track. If you are already an expert, this course may refresh some of your knowledge.
The lectures, examples and exercises require:
1. Some ability of abstract thinking
2. Good background in linear algebra (e.g., matrix and vector algebra, linear independence, basis)
3. Basic background in multivariate calculus (e.g., partial derivatives, basic optimization)
4. Basic knowledge in python programming and numpy

Disclaimer: This course is substantially more abstract and requires more programming than the other two courses of the specialization. However, this type of abstract thinking, algebraic manipulation and programming is necessary if you want to understand and develop machine learning algorithms.

-------------------------------------------------------------------------------------------------------------

## Certificate

1. [Mathematics for Machine Learning: Linear Algebra](https://coursera.org/share/b239011d34f859f8ae32ab15f66d0e91)
2. [Mathematics for Machine Learning: Multivariate Calculus](https://coursera.org/share/f12e5bb9305fa19ef421ce77de75136d)
3. [Mathematics for Machine Learning: PCA](https://coursera.org/share/f7fde7c9dca72f5ce4cd8a49c80d3ca8)
4. [Mathematics for Machine Learning Specialization (Final Certificate)](https://coursera.org/share/d89291af454c1006fb0ed2055f5aa8b5)

--------------------------------------------------------------------------------------------------------------

## References
1. [Mathematics for Machine Learning: Linear Algebra](https://www.coursera.org/learn/linear-algebra-machine-learning?specialization=mathematics-machine-learning)
2. [Mathematics for Machine Learning: Multivariate Calculus](https://www.coursera.org/learn/multivariate-calculus-machine-learning?specialization=mathematics-machine-learning)
3. [Mathematics for Machine Learning: PCA](https://www.coursera.org/learn/pca-machine-learning?specialization=mathematics-machine-learning)

----------------------------------------------------------------------------------------------------------------
## üìù License
The gem is available as open source under the terms of the [MIT License](https://opensource.org/licenses/MIT).
 
-----------------------------------------------------------------------------------------------------------------
